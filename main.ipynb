{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train two different models. One cnn will use the written digit training data to predict the label, while the other, an rnn, will use the spoken audio data to do the same. To make our final predictions, we will use the model which exhibits the highest confidence for each guess. We will procede first by training the cnn: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get labels, explore distribution\n",
    "training_labels = pd.read_csv(\"data/y_train.csv\")[\"label\"]\n",
    "training_labels.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom dataset wrapper\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_file, labels_file=None, is_test=False):\n",
    "        self.data = np.load(data_file)\n",
    "        if not is_test:\n",
    "            self.labels = pd.read_csv(labels_file)[\"label\"]\n",
    "        else:\n",
    "            self.labels = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            sample = {\n",
    "                'data': torch.tensor(self.data[idx].reshape(1, 28, 28), dtype=torch.float),\n",
    "                'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "            }\n",
    "        else:\n",
    "            sample = {\n",
    "                'data': torch.tensor(self.data[idx].reshape(1, 28, 28), dtype=torch.float)\n",
    "            }\n",
    "        return sample\n",
    "\n",
    "\n",
    "def get_data_loaders(data_file, labels_file, batch_size=64, validation_size=0.2):\n",
    "    dataset = CustomDataset(data_file, labels_file)\n",
    "    \n",
    "    #split dataset into training and validation sets\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        np.arange(len(dataset)),\n",
    "        test_size=validation_size,\n",
    "        random_state=21,\n",
    "        stratify=dataset.labels  \n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset = CustomDataset(\"data/x_train_wr.npy\", \"data/y_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom cnn implementation\n",
    "#CNN implementation\n",
    "\n",
    "class cnn_block(nn.Module):\n",
    "  def __init__(self, in_channels = 3, n_hidden = 5, kernel_size = (2, 2)):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Conv2d(in_channels       = in_channels, out_channels = n_hidden, kernel_size = kernel_size, bias=False, padding = 'same'),\n",
    "        nn.BatchNorm2d(num_features = n_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Conv2d(in_channels       = n_hidden, out_channels = in_channels, kernel_size = kernel_size, bias=False, padding = 'same'),\n",
    "        nn.BatchNorm2d(num_features = in_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x + self.layers(x)\n",
    "\n",
    "\n",
    "class linear_block(nn.Module):\n",
    "  def __init__(self, in_features, n_hidden):\n",
    "    super().__init__()\n",
    "    self.in_features = (in_features, n_hidden)\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Linear(in_features = in_features, out_features = n_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(in_features = n_hidden, out_features = in_features),\n",
    "        nn.ReLU()\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x + self.layers(x)\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "  def __init__(self, in_channels = 1, cnn_channels = 1, linear_hidden = 500, n_classes = 10, kernel_size = (3, 3)):\n",
    "    super().__init__()\n",
    "\n",
    "    \n",
    "    self.cnn_layers = nn.Sequential(\n",
    "        cnn_block(in_channels, cnn_channels, kernel_size),\n",
    "        cnn_block(in_channels, cnn_channels, kernel_size),\n",
    "        cnn_block(in_channels, cnn_channels, kernel_size))\n",
    "\n",
    "\n",
    "    self.down_sample = nn.Conv2d(in_channels = in_channels, out_channels = 1, kernel_size = (1, 1))\n",
    "\n",
    "    self.linear_layers = nn.Sequential(\n",
    "        linear_block(28*28, linear_hidden),\n",
    "        linear_block(28*28, linear_hidden)\n",
    "    )\n",
    "    self.last_layer = nn.Linear(28*28, n_classes)\n",
    "\n",
    "    self.all        = nn.Sequential(\n",
    "        self.cnn_layers,\n",
    "        self.down_sample,\n",
    "        nn.Flatten(),\n",
    "        self.linear_layers,\n",
    "        self.last_layer,\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.all(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train cnn\n",
    "\n",
    "#training \n",
    "def train_cnn(model, train_loader, val_loader, optimizer, criterion, epochs=5, device='cpu'):\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/ {epochs}\", unit=\"batch\"):\n",
    "            inputs, labels = batch['data'].to(device), batch['label'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = correct / total\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, labels = batch['data'].to(device), batch['label'].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, labels = batch['data'].to(device), batch['label'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "    true_labels = np.array(true_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and validation sets with 80-20 split\n",
    "batch_size = 64\n",
    "validation_size = 0.2\n",
    "train_loader, val_loader = get_data_loaders(\"data/x_train_wr.npy\", \"data/y_train.csv\", batch_size=batch_size, validation_size=validation_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next portion of the code tries out different hyperparams by training different models on a small subset of the training data (1/5 of the training data) for only 3 epochs. It takes a bit to run, but after expirementing, {'cnn_channels': 3, 'linear_hidden': 25, 'kernel_size': (5, 5)} TENDS to work the best (although other hyperparams are close) with an F1 score of roughly .94 (which is pretty good considering it's only training on a small subset of the total data). If you want to check my hyperparam comparision, you can simply change the variable below to True to run this process. Otherwise, we simply default to the previously described hyperparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "waste_a_lot_of_time = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a smaller dataset for hyperparam comparisons \n",
    "hyper_loader, hyper_val_loader = get_data_loaders(\"data/x_train_wr.npy\", \"data/y_train.csv\", batch_size=batch_size, validation_size=.8) #thus we train on .2 of given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: cnn_channels=2, linear_hidden=25, kernel_size=(3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 3:   0%|          | 0/188 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 3: 100%|██████████| 188/188 [00:07<00:00, 24.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.7344, Train Accuracy: 0.7732, Validation Loss: 0.3110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/ 3: 100%|██████████| 188/188 [00:06<00:00, 29.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.3263, Train Accuracy: 0.8991, Validation Loss: 0.2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/ 3: 100%|██████████| 188/188 [00:05<00:00, 33.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.2719, Train Accuracy: 0.9143, Validation Loss: 0.2163\n",
      "Validation F1 for cnn_channels=2, linear_hidden=25, kernel_size=(3, 3): 0.933068204276496\n",
      "Training model: cnn_channels=2, linear_hidden=25, kernel_size=(5, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 3: 100%|██████████| 188/188 [00:06<00:00, 27.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 1.1764, Train Accuracy: 0.6155, Validation Loss: 0.4005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/ 3: 100%|██████████| 188/188 [00:06<00:00, 29.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.3610, Train Accuracy: 0.8867, Validation Loss: 0.2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/ 3: 100%|██████████| 188/188 [00:06<00:00, 26.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.2665, Train Accuracy: 0.9161, Validation Loss: 0.2153\n",
      "Validation F1 for cnn_channels=2, linear_hidden=25, kernel_size=(5, 5): 0.9316791189641777\n",
      "Training model: cnn_channels=2, linear_hidden=50, kernel_size=(3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 3: 100%|██████████| 188/188 [00:06<00:00, 30.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.8485, Train Accuracy: 0.7270, Validation Loss: 0.3144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/ 3: 100%|██████████| 188/188 [00:06<00:00, 31.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.3521, Train Accuracy: 0.8838, Validation Loss: 0.2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/ 3: 100%|██████████| 188/188 [00:06<00:00, 31.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.2850, Train Accuracy: 0.9084, Validation Loss: 0.1978\n",
      "Validation F1 for cnn_channels=2, linear_hidden=50, kernel_size=(3, 3): 0.9366197255230408\n",
      "Training model: cnn_channels=2, linear_hidden=50, kernel_size=(5, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 3: 100%|██████████| 188/188 [00:06<00:00, 26.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.9097, Train Accuracy: 0.7059, Validation Loss: 0.3857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/ 3: 100%|██████████| 188/188 [00:06<00:00, 27.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.3792, Train Accuracy: 0.8815, Validation Loss: 0.2735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/ 3: 100%|██████████| 188/188 [00:07<00:00, 26.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.3038, Train Accuracy: 0.9072, Validation Loss: 0.2502\n",
      "Validation F1 for cnn_channels=2, linear_hidden=50, kernel_size=(5, 5): 0.9231755762296862\n",
      "Training model: cnn_channels=3, linear_hidden=25, kernel_size=(3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 3: 100%|██████████| 188/188 [00:06<00:00, 31.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.7474, Train Accuracy: 0.7630, Validation Loss: 0.3258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/ 3: 100%|██████████| 188/188 [00:06<00:00, 31.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.3402, Train Accuracy: 0.8931, Validation Loss: 0.2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/ 3: 100%|██████████| 188/188 [00:06<00:00, 30.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.2614, Train Accuracy: 0.9193, Validation Loss: 0.2128\n",
      "Validation F1 for cnn_channels=3, linear_hidden=25, kernel_size=(3, 3): 0.9358380432730025\n",
      "Training model: cnn_channels=3, linear_hidden=25, kernel_size=(5, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 3: 100%|██████████| 188/188 [00:07<00:00, 26.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.5987, Train Accuracy: 0.8087, Validation Loss: 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/ 3: 100%|██████████| 188/188 [00:07<00:00, 25.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.2972, Train Accuracy: 0.9066, Validation Loss: 0.2212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/ 3: 100%|██████████| 188/188 [00:08<00:00, 23.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.2248, Train Accuracy: 0.9295, Validation Loss: 0.2182\n",
      "Validation F1 for cnn_channels=3, linear_hidden=25, kernel_size=(5, 5): 0.9300554272582321\n",
      "Training model: cnn_channels=3, linear_hidden=50, kernel_size=(3, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 3: 100%|██████████| 188/188 [00:07<00:00, 24.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 1.2359, Train Accuracy: 0.5887, Validation Loss: 0.3975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/ 3: 100%|██████████| 188/188 [00:07<00:00, 24.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.3579, Train Accuracy: 0.8844, Validation Loss: 0.2654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/ 3: 100%|██████████| 188/188 [00:06<00:00, 30.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.2803, Train Accuracy: 0.9115, Validation Loss: 0.2305\n",
      "Validation F1 for cnn_channels=3, linear_hidden=50, kernel_size=(3, 3): 0.92653722375222\n",
      "Training model: cnn_channels=3, linear_hidden=50, kernel_size=(5, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 3: 100%|██████████| 188/188 [00:07<00:00, 23.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.7957, Train Accuracy: 0.7362, Validation Loss: 0.2790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/ 3: 100%|██████████| 188/188 [00:07<00:00, 25.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3, Train Loss: 0.3079, Train Accuracy: 0.9035, Validation Loss: 0.1972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/ 3: 100%|██████████| 188/188 [00:07<00:00, 25.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3, Train Loss: 0.2273, Train Accuracy: 0.9277, Validation Loss: 0.1632\n",
      "Validation F1 for cnn_channels=3, linear_hidden=50, kernel_size=(5, 5): 0.9494603215650365\n",
      "Best Hyperparameters: {'cnn_channels': 3, 'linear_hidden': 50, 'kernel_size': (5, 5)}\n",
      "Best Validation Accuracy: 0.9494603215650365\n"
     ]
    }
   ],
   "source": [
    "#test different hyperparams \n",
    "\n",
    "hyperparameters = {\n",
    "    'cnn_channels': [2, 3],  # Vary the number of channels in the CNN layers\n",
    "    'linear_hidden': [25, 50],  # Vary the number of hidden units in linear layers\n",
    "    'kernel_size': [(3, 3), (5, 5)]  # Vary the kernel size of the convolutional layers\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "best_f1 = 0.0\n",
    "best_hyperparameters = {}\n",
    "if (waste_a_lot_of_time):\n",
    "    for cnn_channels in hyperparameters['cnn_channels']:\n",
    "        for linear_hidden in hyperparameters['linear_hidden']:\n",
    "            for kernel_size in hyperparameters['kernel_size']:\n",
    "                print(f\"Training model: cnn_channels={cnn_channels}, linear_hidden={linear_hidden}, kernel_size={kernel_size}\")\n",
    "                model = CNNClassifier(cnn_channels=cnn_channels, linear_hidden=linear_hidden, kernel_size=kernel_size)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                train_cnn(model, hyper_loader, hyper_val_loader, optimizer, criterion, epochs=3)\n",
    "                val_accuracy = validate(model, hyper_val_loader)\n",
    "                print(f\"Validation F1 for cnn_channels={cnn_channels}, linear_hidden={linear_hidden}, kernel_size={kernel_size}: {val_accuracy}\")\n",
    "                if val_accuracy > best_f1:\n",
    "                    best_f1 = val_accuracy\n",
    "                    best_hyperparameters = {'cnn_channels': cnn_channels, 'linear_hidden': linear_hidden, 'kernel_size': kernel_size}\n",
    "else: \n",
    "    best_hyperparameters = {'cnn_channels': 3, 'linear_hidden': 25, 'kernel_size': (5, 5)}\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "print(\"Best Validation Accuracy:\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 5:   0%|          | 0/750 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/ 5: 100%|██████████| 750/750 [00:30<00:00, 24.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 0.5380, Train Accuracy: 0.8301, Validation Loss: 0.2232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/ 5: 100%|██████████| 750/750 [00:32<00:00, 23.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Train Loss: 0.2321, Train Accuracy: 0.9310, Validation Loss: 0.1806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/ 5: 100%|██████████| 750/750 [00:35<00:00, 21.18batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Train Loss: 0.1940, Train Accuracy: 0.9401, Validation Loss: 0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/ 5: 100%|██████████| 750/750 [00:40<00:00, 18.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Train Loss: 0.1740, Train Accuracy: 0.9474, Validation Loss: 0.1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/ 5: 100%|██████████| 750/750 [00:37<00:00, 19.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 0.1601, Train Accuracy: 0.9509, Validation Loss: 0.1382\n"
     ]
    }
   ],
   "source": [
    "#train model with selected hyperparams\n",
    "best_model = CNNClassifier(cnn_channels=best_hyperparameters['cnn_channels'], linear_hidden=best_hyperparameters['linear_hidden'], kernel_size=best_hyperparameters['kernel_size'])\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_cnn(best_model, train_loader, val_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_loader(data_file, batch_size=64):\n",
    "    test_dataset = CustomDataset(data_file, is_test=True)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False \n",
    "    )\n",
    "    return test_loader\n",
    "\n",
    "test_data_loader = get_test_loader(\"data/x_test_wr.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predicted labels\n",
    "best_model.eval()  # set the mode to eval\n",
    "predicted_labels = []\n",
    "confidence_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        inputs = batch['data'].to(device)  \n",
    "        outputs = best_model(inputs)\n",
    "        probabilities = nn.functional.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "        confidence_scores.extend(probabilities.gather(1, predicted.view(-1, 1)).squeeze().cpu().numpy()) #only add the highest confidence score, or the score of the predicted label\n",
    "\n",
    "# Convert predictions to numpy array\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "confidence_scores = np.array(confidence_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cnn_model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 507)\n"
     ]
    }
   ],
   "source": [
    "#now we will make a model that predicts the label based on the spoken audio\n",
    "\n",
    "#get the data\n",
    "audio_training_data = np.load(\"data/x_train_sp.npy\")\n",
    "print(audio_training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our model, we will use a simple RNN-style model to predict labels based on our audio\n",
    "class RNNBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0):\n",
    "        super(RNNBlock, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, linear_hidden, num_classes):\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.rnn_layers = RNNBlock(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            LinearBlock(hidden_size, linear_hidden),\n",
    "            LinearBlock(linear_hidden, linear_hidden)\n",
    "        )\n",
    "        self.output_layer = nn.Linear(linear_hidden, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.rnn_layers(x)\n",
    "        out = self.linear_layers(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old shape:507\n",
      "New shape: 520\n"
     ]
    }
   ],
   "source": [
    "print(\"Old shape:\" + str(audio_training_data.shape[1]))\n",
    "\n",
    "#change the length of each sample from 507 to 520 (a more convenient size for our model) by padding each sample with 0s at the end\n",
    "audio_training_data = np.pad(audio_training_data, ((0, 0), (0, 13)), mode='constant') \n",
    "\n",
    "#convert into tensors\n",
    "audio_training_data_tens = torch.from_numpy(audio_training_data).float()\n",
    "training_labels_tens = torch.from_numpy(np.array(training_labels)).long()\n",
    "\n",
    "print(\"New shape: \" + str(audio_training_data.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 ...\n",
      "Epoch 1/5, Loss: 2.3057, Accuracy: 0.0924\n",
      "epoch 1 ...\n",
      "Epoch 2/5, Loss: 2.3060, Accuracy: 0.0925\n",
      "epoch 1 ...\n",
      "Epoch 3/5, Loss: 2.3057, Accuracy: 0.0936\n",
      "epoch 1 ...\n",
      "Epoch 4/5, Loss: 2.3057, Accuracy: 0.0928\n",
      "epoch 1 ...\n",
      "Epoch 5/5, Loss: 2.3058, Accuracy: 0.0927\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "rnn_model = RNNClassifier(520, 128, 2, 256, 10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=.01, momentum=.9)\n",
    "\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch 1 ...\")\n",
    "    running_loss = 0.0\n",
    "    running_accuracy = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i in range(0, len(audio_training_data_tens), batch_size):\n",
    "        inputs = audio_training_data_tens[i:i+batch_size]\n",
    "        target_labels = training_labels_tens[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn_model(inputs)\n",
    "        loss = criterion(outputs, target_labels)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += target_labels.size(0)\n",
    "        running_accuracy += (predicted == target_labels).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / (len(audio_training_data_tens) / batch_size)\n",
    "    epoch_accuracy = running_accuracy / total_samples\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save predictions\n",
    "predictions_df = pd.DataFrame({'row_id': np.array([i for i in range(len(predicted_labels))]), 'label': predicted_labels.flatten()})\n",
    "predictions_df.to_csv('Caleb Elizondo preds.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
